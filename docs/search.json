[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LearningDiary",
    "section": "",
    "text": "Preface\nThis is a Learning Diary of CASA0023 Remote Sensing."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "LearningDiary",
    "section": "About me",
    "text": "About me\n\n\n\nyy’s portrait\n\n\nKKKKKenny,"
  },
  {
    "objectID": "index.html#about-layout-of-learning-diary",
    "href": "index.html#about-layout-of-learning-diary",
    "title": "LearningDiary",
    "section": "About Layout of Learning Diary",
    "text": "About Layout of Learning Diary\nYou can also click bar in the left to navigate to corresponding page\n\nWeek 01\nWeek 02\nWeek 03"
  },
  {
    "objectID": "Week01.html",
    "href": "Week01.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Week02.html",
    "href": "Week02.html",
    "title": "Week 02 Portfolio",
    "section": "",
    "text": "If that preview doesn’t work, please click Link to find out more."
  },
  {
    "objectID": "Week03.html",
    "href": "Week03.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Week01.html#theoretical-part",
    "href": "Week01.html#theoretical-part",
    "title": "Week01 Introduction to remote sensing",
    "section": "1. Theoretical Part",
    "text": "1. Theoretical Part\n\n\n\nMindmap for W1 lecture part\n\n\n\n1.1. Different Sensors\n\n\n\n\n\n\n\n\n\n\n\nEnergy\nReceive\nE.g.,\nApplications\n\n\n\n\nPassive\n❌\nReflected energy from sun (electromagnetic)\nHuman eye, Satellite sensor\nRemote Sensing, meteorological observation, astronomy\n\n\nActive\n✅\nElectromagnetic that actively emit\nRadar, X-ray, LiDAR\nranging, velocity measurement, terrain mapping, and target identification\n\n\n\n Source: NASA\nPassive sensors are more widely used in remote sensing of the Earth and environmental monitoring because they can provide multi-band information on a global scale.\n\nThese sensors do not need to actively send signals to the target, but rely on natural radiation, thus enabling energy-efficient, wide-area observations. For this reason, passive sensors are often mounted on satellites to enable remote sensing observations on a global scale.\nIn addition, passive sensors typically cover multiple wavelength bands, including visible, infrared, and ultraviolet. This broad-spectrum coverage allows them to capture a wide range of features and information about the Earth’s surface, from vegetation cover to surface temperature, in different wavelength bands.\n\n\n\n1.2. Different Orbits\n\n\n\n\n\n\n\n\n\n\nDefinition\nE.g.,\nApplications\n\n\n\n\nGeosynchronous Orbit (GSO)\nSatellite’s period matches the Earth’s rotation period, making the satellite’s position relatively fixed above the Earth\nThe GOES series (Geostationary Operational Environmental Satellites) by the United States and the Meteosat series by Europe\nWeather Forecasting, Climate Monitoring, and communications\n\n\nGeostationary Orbit (GEO)\nSatellite’s speed matches the Earth’s rotation, allowing it to remain stationary relative to a point on the Earth’s surface.\nThe International Telecommunications Satellite Organization, SES (Société Européenne des Satellites)\nCommunication, Observing Earth’s weather, environment, and climate changes, providing valuable remote sensing data\n\n\n\n\n\n1.3. Different Interactions\n\n1.3.1. Earth’s Surface\n\nEnergy will be obsorbed by the surface\nEnergy being transmitted through the surface\n\n Source:Ghimire, 2021\n\nBidirectional Reflectance Distribution Function (BRDF):\nDefinition: A two-dimensional function used to represent the intensity distribution of light entering a material or surface and then exiting the light at the other end.\nApplication: Simulates real-life light conditions, detects particle concentrations in the atmosphere, and detects air humidity in the soil.\nReactions that occur when interacting with the Earth’s surface：\nPolarization: When electromagnetic waves are affected by interference, scattering or reflection, the direction of vibration changes. It is often used to distinguish between different material properties because different types of materials have different polarization responses.\nFluorescence: A substance is excited to emit light that has a longer wavelength. It can usually be used to detect certain specific compounds or biological processes, and is therefore used in fields such as environmental pollution detection and soil characterisation.\n\n\n\n1.3.2. Atmosphere\nAtmospheric scattering\n Source:Bovensmann et al., 2011\nQ: Why is the sky blue (provided that air particles)\nA: Because when the sun is overhead, the shorter wavelength of blue light (as shown in the figure below) is more easily scattered, and thus the sky is observed to be blue. Whereas at sunset, the blue light is scattered away by the atmosphere and the orange-red light passes through the atmosphere into the eye, hence the sky is orange-red.\n Source: The University of Waikato Te Whare Wānanga o Waikato\nSimilarly, seawater has the ability to absorb and scatter. What we usually observe is blue light scattered by seawater.\nIn addition, black colour indicates that all light is absorbed and there is no reflection, scattering or projection. Therefore, the sea floor is black without light.\nWhite, on the other hand, is the result of all colours being absorbed in equal amounts and is the result of mixing various colours together.\n\n\n\n1.4. Data Format\nMajority of remotely sensed data is Raster which is built from pixel. I think this link analysing the difference between a Raster and a Vector is still quite well written and explains what a Raster is quite clearly. In addition, this link also explain raster very well. They also have other information like “Raster bands”, “Image and raster data organization” and so on.\n\nSeveral File Types: BIL, BSQ, BIP, GeoTIFF(Most seen). This Link provides a detailed introduction to those kind of files with examples.\nResolution:\n\n\nRadiometric: The amount of information in each pixel.\n\n\n8-bit can hold 0-255 possibilities, 11-bit can hold 0-2047 possibilities. Here it is perhaps more superficially understood that subtle colour differences can or cannot be represented.\nIn addition, different numbers of spectral channels correspond to different spectral ranges measured on different bands. Multiple spectral channels allow the capture of information in different bands of the surface, such as visible light, infrared, etc. For example, AVIRIS has 224 spectral channels.\n\n\nSpatial: The size of the actual area represented by each pixel point.\n\n\nThe higher the resolution, the finer the surface features captured.\n\n Source: NASA\n\nSpectral：Ability to distinguish spectral detail over different bands.\n\n\nHigher spectral resolution indicates that the data has more information in more bands and is able to distinguish between more landmark features and material composition.\nIn data, each band is stored in a dedicated grating layer. Spectral data can be discrete or continuous.\n\n Source: NIREOS\n\nTemporal: Time interval for acquiring data.\n\n\nThe following figure shows the distribution of time intervals versus pixel resolution for different satellites.\n\n Source: ESRI"
  },
  {
    "objectID": "Week01.html#practical-part",
    "href": "Week01.html#practical-part",
    "title": "Week01 Introduction to remote sensing",
    "section": "Practical Part",
    "text": "Practical Part\n(Waiting for updating)"
  },
  {
    "objectID": "Week01.html#what-i-learned-from-mistakes.",
    "href": "Week01.html#what-i-learned-from-mistakes.",
    "title": "Week01 Introduction to remote sensing",
    "section": "What I learned from mistakes.",
    "text": "What I learned from mistakes.\n(Waiting for updating)"
  },
  {
    "objectID": "Week01.html#reflection",
    "href": "Week01.html#reflection",
    "title": "Week01 Introduction to remote sensing",
    "section": "Reflection",
    "text": "Reflection\nThe first week was a relatively basic introductory class, so overall it wasn’t too difficult to get a basic knowledge of an unfamiliar field.\nAlthough I had forgotten a bit about the physics when it came to wavelengths and frequencies, it was good to see that only some concepts were covered. The subsequent understanding and working principle are not affected.\nIn addition, the storage and processing of remote sensing data (raster) in class was also very confusing. But the good thing is that the Drop-in session immediately following was able to talk about and solve this problem. Each pixel point has a unique spectral map (if it’s a multi-band image), usually synthesised from Red, Green, and Blue. But it is also possible to choose different wavelengths for the synthesis, depending on the needs of the study.\nI’m thankful to ArcGIS, ESRI, and NASA for really providing a lot of valid information in their offical documents to help me make sense of it. For example, this link is a detailed description of the Raster data. Also thanks to ChatGPT for being able to give me some basic Q&A’s."
  }
]