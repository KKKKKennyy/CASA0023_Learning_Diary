<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>LearningDiary - Week 08 Classification II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Week09.html" rel="next">
<link href="./Week07.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Week08.html">Week 08 Classification II</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">LearningDiary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 01 Introduction to remote sensing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 02 Portfolio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 03 Remote sensing data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 04 SAR applications &amp; Policies</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 06 Introduction to GEE</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 07 Classification I</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week08.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Week 08 Classification II</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 0</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary">1. Summary</a>
  <ul class="collapse">
  <li><a href="#object-based-image-analysis" id="toc-object-based-image-analysis" class="nav-link" data-scroll-target="#object-based-image-analysis">1.1 Object-based Image Analysis</a></li>
  <li><a href="#sub-pixel-analysis" id="toc-sub-pixel-analysis" class="nav-link" data-scroll-target="#sub-pixel-analysis">1.2 Sub-pixel Analysis</a></li>
  <li><a href="#accuracy-assessment" id="toc-accuracy-assessment" class="nav-link" data-scroll-target="#accuracy-assessment">1.3 Accuracy assessment</a></li>
  </ul></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">2. Application</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection">3. Reflection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Week 08 Classification II</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">1. Summary</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Week8Mindmap.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Mindmap of W8 Summary</figcaption>
</figure>
</div>
<section id="object-based-image-analysis" class="level3">
<h3 class="anchored" data-anchor-id="object-based-image-analysis">1.1 Object-based Image Analysis</h3>
<p>Last week I was lamenting how computers are supposed to recognise categories like the human eye. It turns out it’s through data computation. But in the midst of this week’s study came an algorithm that is very similar to human visual perception: object-based image analysis (OBIA). “Think objects, not pixels” is how I would summarise this approach. The main things involved in this method are segmentation and classification.</p>
<p><img src="img/OBIA.png" class="img-fluid" alt="Pagosa Springs, Colorado, USA: Semi-automated object based classification of 1m 4-band NAIP. Classes include trees, lower vegetation, impervious type surfaces and hydrological features"> <strong><em>Pagosa Springs, Colorado, USA: Semi-automated object based classification of 1m 4-band NAIP. Classes include trees, lower vegetation, impervious type surfaces and hydrological features.</em></strong></p>
<p>Source:<a href="https://landinfo.com/image-classification-object-based-image-analysis-obia/">Landinfo</a></p>
<p>Firstly, there is segmentation, where obia takes a small pixel image and splits it into vector objects. Simply understood, this is the process of grouping similar pixels into objects, much like the human eye does. Once you have these segmented objects, you can use its spectral, geometric, and spatial properties to divide the land cover. I view each segmented object as a Feature, a gemtry that contains additional information. then comes the classification, obia will use the shape, size and spectral properties of the object to classify each object. This is an iterative process, according to the motion picture provided in class. That is, by iteratively adjusting the segmentation parameters (e.g., segmentation scale, shape, and compactness parameters), the most suitable segmentation result for a particular application can be found.</p>
<p>The following results based on OBIA and using the CART method to assign land cover categories show the land cover categories for the Tanzanian capital city (urban is red, bare-earth is grey, grass is light yellow and forest is green):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/OBIA_Practical.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Practical Result</figcaption>
</figure>
</div>
<p>The results do seem to be missing some detail, perhaps due to the presence of superpixels. The next method introduced is able to show the information inside the pixel more clearly, which is Sub-pixel Analysis.</p>
</section>
<section id="sub-pixel-analysis" class="level3">
<h3 class="anchored" data-anchor-id="sub-pixel-analysis">1.2 Sub-pixel Analysis</h3>
<p>Even within a single pixel, different substances on the ground (e.g.&nbsp;different types of vegetation, soil or water) can be mixed. However, in conventional analyses the reflectance value of a pixel is a weighted average of the material reflectance of the material within the pixel. In most cases, this leads to a loss of information. Therefore, sub-pixel analysis aims to distinguish and quantify the proportion of each component in these mixed pixels, thus recovering some of the lost spatial information. The following is the result obtained by applying sub-pixel analysis in practical:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/SPA_Practical.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Practical Result</figcaption>
</figure>
</div>
<p>It can be clearly seen that there are more details in the classification than OBIA, which seems to make the results more realistic and reliable. But how to quantitatively evaluate the results is also a problem worth thinking about, so the next part is the Accuracy assessment.</p>
</section>
<section id="accuracy-assessment" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-assessment">1.3 Accuracy assessment</h3>
<p>The main centrepiece of the assessment of the accuracy of classification problems is the Confusion Matrix. The Confusion Matrix, which is used to show the relationship between the actual categories and the model’s predicted categories, provides an intuitive way to understand the model’s performance on each category, including its accuracy, false alarm rate, miss rate, and other key metrics.</p>
<p><img src="img/ConfusionMatrix.png" class="img-fluid" alt="Confusion Matrix"> Source: <a href="https://glassboxmedicine.com/2019/02/17/measuring-performance-the-confusion-matrix/">Draelos, 2019</a></p>
<p>In a binary classification problem, the confusion matrix consists of four components: - <strong>True Positives (TP)</strong>: the number of classes that the model correctly predicts as positive. - <strong>False Positives (FP)</strong>: the number of classes that the model incorrectly predicts as positive (actually negative). - <strong>True Negatives (TN)</strong>: the number of classes that the model correctly predicts as negative. - <strong>False Negatives (FN)</strong>: the number of negative classes that the model incorrectly predicts (actually positive classes).</p>
<p>The confusion matrix allows for the calculation of a variety of assessment metrics:</p>
<p><strong>Accuracy</strong>: the proportion of all correctly predicted observations to the total number of observations. The formula is</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]</span></p>
<p><strong>Precision</strong>: the accuracy of the positive class prediction, i.e., the proportion of true examples that are predicted to be positive. The formula is</p>
<p><span class="math display">\[
\text{Precision} = \frac{TP}{TP + FP}
\]</span></p>
<p><strong>Recall</strong>, also known as the true instance rate: the proportion of positive class observations captured by the model. The formula is</p>
<p><span class="math display">\[
\text{Recall} = \frac{TP}{TP + FN}
\]</span></p>
<p><strong>F1 Score</strong>: the reconciled average of precision and recall, used to measure the balance between model accuracy and recall. The formula is</p>
<p><span class="math display">\[
\text{F1 Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]</span></p>
</section>
</section>
<section id="application" class="level2">
<h2 class="anchored" data-anchor-id="application">2. Application</h2>
<p>The first is that there is <a href="https://beta.source.coop/">an open source machine learning website</a> on EO training.</p>
<p><a href="https://www.mdpi.com/2073-445X/12/1/99">Matarira et al.</a> show that the convenience of the simple non-iterative clustering (SNIC) algorithm in Google Earth Engine (GEE) offers Geographic Object-Based Image Analysis (GEOBIA) the potential to map the spatial morphology of deprived neighbourhoods in the complex built environment of Durban. They demonstrated the effectiveness of OBIA in GEE mapping applications by integrating Sentinel-1, Sentinel-2 and PlanetScope satellite data to enable object-based mapping of informal settlements in GEE. But OBIA’s constant search for segmentation classification steps can be very time-consuming when encountering large-scale or high-resolution datasets. And I think one of the major factors for the success of this research is that the data provided by PlanetScope is of high enough resolution so that OBIA can segment and classify the objects well.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S1364815219300490">Vos et al.</a> completed the development of CoastSat on the GEE platform, which utilises sub-pixel resolution boundary segmentation for shoreline detection and possesses high accuracy. However, it is rather unfortunate not to see comparisons between different models. For example, would there be a difference in performance between a linear spectral unmixing model and a linear combination of reflectance. And the article doesn’t provide an in-depth explanation of how the algorithm determines the proportion of surface types within a pixel, perhaps also because the models themselves are less interpretable. But nonetheless, the results of the algorithm runs can provide accurate results and INSIGHTS for policy makers, or maybe that’s the beauty of sub-pixel analysis.</p>
</section>
<section id="reflection" class="level2">
<h2 class="anchored" data-anchor-id="reflection">3. Reflection</h2>
<p>Parente et al.&nbsp;<a href="https://www.mdpi.com/2072-4292/11/23/2881">(2019)</a> evaluated the performance of machine learning approaches, including deep learning algorithms implemented using TensorFlow, for mapping pasturelands in Central Brazil. Wang et al.&nbsp;<a href="https://ieeexplore.ieee.org/document/8989826">(2020)</a> proposed a method that combines GEE with a multiscale convolutional neural network (MSCNN) for urban water extraction from Landsat images. Balaniuk et al.&nbsp;<a href="https://www.mdpi.com/1424-8220/20/23/6936">(2020)</a> explored the use of deep learning methods to detect surface mines and mining tailings dams in Brazil using multispectral Sentinel-2 satellite imagery processed in the GEE platform.</p>
<p>More and more research is trying to combine GEE and deep learning, and this trend is really in line with the main theme of the AI era. Although deep learning frameworks or models are still like a black box, it is not easy to explain the principles behind the theories. But from a practical point of view, it can provide more advanced recognition or more accurate classification, offering potential solutions to more complex problems. Like Sub-pixels analysis, it may not be necessary to specify exactly how to infer the proportion of land types within a pixel, just learn to use it and analyse the results. After this week’s study and research, I’m even more convinced about last week’s resource integration. Despite the advantages that GEE already has, Jean has some disadvantages that need to be supplemented by other resources. Hopefully in the future I can empower GEE with deep learning as well.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Week07.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Week 07 Classification I</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Week09.html" class="pagination-link">
        <span class="nav-page-text">Week 0</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>